{"body": "\nI just posted the following on the main GH forum.\n\n\"I know this has been discussed in the past but I would like to ask if there are any new considerations relating to an optimal hardware setup with the upcoming Rhino and GH updates in mind.\"\n\n\n\nAre there any additional considerations relating to Honeybee and Ladybug, and programs they link to? I will be conducting a lot of energy and daylighting analysis and also hope to get into CFD with butterfly.\n\n\n\nI would appreciate any input!\n", "attachments": [], "created_by_name": "Ernst Bay", "created_at": "November 3, 2016 at 12:56pm", "created_by": "ErnstBay", "topic": "Hardware suggestions - Rhino/GH update", "replies": [{"body": "\nHi Ernst,\n\nI don't think there is a single answer to this question. It depends on the type of the analysis you are trying to run.\n\nGenerally speaking the more RAM you have the better. Specially when it comes to butterfly/CFD/OpenFOAM you want to make sure you have enough memory for snappyHexMesh.\n\nBoth Radiance and OpenFoam can take advantage of parallel runs in non-Windows environments. Currently OpenFoam is using dockers to run OpenFOAM from Windows which is what Butterfly is using so you can run the analysis in Parallel even from Windows. In both cases having more cpus will decrease the time of the analysis.\n\nHere is two benchmarking tests for Radiance: [1](https://github.com/markstock/Radiance-Benchmark4)\u00a0and [2](http://markjstock.org/pages/rad_bench_old.html), and [here is benchmarking test](http://www.jeplus.org/wiki/doku.php?id=docs:eplustest)\u00a0for EnergyPlus. You can find it both for the computer speed and processor speed.\n\nMostapha\n", "attachments": [], "created_by_name": "Mostapha Sadeghipour Roudsari", "created_at": "November 10, 2016 at 4:50pm", "created_by": "MostaphaSadeghipour", "replies": [{"body": "\nThank you for your thoughts, Mostapha.\n", "attachments": [], "created_by_name": "Ernst Bay", "created_at": "November 15, 2016 at 12:50pm", "created_by": "ErnstBay", "replies": []}]}, {"body": "\nTry to get a NIVIDA CUDA-enabled graphics card and install the Radiance ad-on that allows calcs to be run with GPU.<br/><br/>[http://web.mit.edu/SustainableDesignLab/projects/Accelerad/](http://web.mit.edu/SustainableDesignLab/projects/Accelerad/)\n", "attachments": [], "created_by_name": "Ludvig Haav", "created_at": "November 11, 2016 at 5:54am", "created_by": "LudvigNyman", "replies": [{"body": "\nThank you. I was not aware of this program.\n", "attachments": [], "created_by_name": "Ernst Bay", "created_at": "November 15, 2016 at 12:51pm", "created_by": "ErnstBay", "replies": []}]}, {"body": "\nAny thoughts on Nvidia Quadro vs. Geforce. The high end Quadros come with ECC memory. Is that worth investing in since I may be running simulations with CUDA? At the same time, a guy from Puget said that for the same money you get much better CUDA performance with a Geforce card. This seems to boil down to: is 16Gb of ECC memory (as opposed to 8Gb non-ECC) worth $1,000.\u00a0\n", "attachments": [], "created_by_name": "Ernst Bay", "created_at": "November 15, 2016 at 2:12pm", "created_by": "ErnstBay", "replies": []}]}