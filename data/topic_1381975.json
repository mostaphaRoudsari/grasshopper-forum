{"body": "\nHi all,\n\n\u00a0\n\nI want to take advantage of all the unused desktops that my company has sitting around at night. I'm searching for a way to create something like a render farm or cluster computing through GH.\n\n\u00a0\n\nWhen using GH as a translator to run multiple iterations through 3rd party programs like Radiance or E+ (honeybee modules), the calc doesn't live in GH/rhino. GH simply calls these programs. Unfortunately, every iteration is called in series. Once one ends, the next begins.\u00a0I'd like to send these iterations to multiple computers on a server so that I can run in parallel and reduce my wall-clock time.\n\n\u00a0\n\nI'd like to generate all 500 batch files from one machine, then somehow call those routines on other computers on my network, say 100 runs on 5 machines. Or 5 runs on 100 machines (even better!).\u00a0I hope this is possible because we are not splitting any single computation between multiple machines. We only want to call\u00a0unique runs across a network.\u00a0\n\n\u00a0\n\nHas anyone explored this? If we figure this out, companies or students could take advantage of all the unused desktops in offices or computer labs\u00a0to calculate large sets overnight. Which would be amazing.\n\n\u00a0\n\nThanks for your help.\n\n-Leland\n", "attachments": [], "created_by_name": "Leland Curtis", "created_at": "October 19, 2015 at 4:29pm", "created_by": "LelandCurtis", "topic": "Running Honeybee in parallel across multiple computers in a network", "id": "topic_1381975"}