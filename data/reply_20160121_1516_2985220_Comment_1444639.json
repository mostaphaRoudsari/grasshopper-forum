{"body": "\nElzine,\n\n\n\nI agree that optimization is limited. I strongly prefer using tools like Honeybee/Design Explorer to map out all possibilities and understand the underlying drivers of performance. Before we try to hit\u00a0the bullseye, let's make sure we are shooting at the right target. \"Where to go from here\" is a great way to put it. I couldn't agree more. Also, small decisions made in early design (massing, orientation, program layout)\u00a0can have a huge impact on overall performance, while optimizing one fa\u00e7ade element in DD may be splitting hairs with limited benefit.\n\n\u00a0\n\nI think these tools have the ability to calculate better information and better communicate that information. In the end, adopting an informed design process, where the designers actually adapt their designs\u00a0based on\u00a0performance data, is\u00a0critical for these tools to be effective.\u00a0So it's not enough to just calculate the next best metric, we need to inform design decisions. I'm curious what NZ designers think. Good luck with your workshops and focus groups. I hope you share the results with others on this forum.\n\n\u00a0\n\nI agree, HB makes the old school radiance interface look archaic. I could never go back.\n\nCurrent HB components analyze results from a single zone and allow for a lot of customization of the data. I think most people develop their own custom analysis GH scripts to create custom graphics, graphs and metrics from the raw data output by HB. Design Explorer fills the gap of exploring multi-run data sets. Check out this link (Abraham included it in his post) [http://tt-acm.github.io/DesignExplorer/](http://tt-acm.github.io/DesignExplorer/). Play around with the single zone energy model (middle option).\n\n\u00a0\n\nI don't see a\u00a0way around reimporting the data back into GH for post-processing of the raw data.\u00a0On the daylighting side HB has components to take the raw .ill file and convert it into DA calcs. If you create your idfs in series, you can perform this post-processing automatically after each file is run before iterating to the next option.\n\n\u00a0\n\nTo streamline\u00a0your current TA\u00a0calc process, I would automate a script to cycle through all of your idf file names individually\u00a0and record the outputs into a format that DE can open. Essentially you would calculate TA from each individual\u00a0csv file, record the results and unique input\u00a0parameters that identify the run, then move to the next idf file. Once the automated process is done you can review the entire TA data set in DE. If it is automated, the fact that TA requires a lot of extra components isn't a big deal. It will be tricky to save 8760 data though, as DE requires single number inputs. Perhaps you can create a json file that includes colored 8760 plots, that way as you go through DE you see the 8760 data associated with each run. It would work similar to how the example DE file captures the DA calc as a colored grid on the floor.\n\n\u00a0\n\nI don't know of any sensitivity analysis components other than Design Explorer and octopus. I hope they do what you need. Good luck.\n", "attachments": [], "created_by_name": "Leland Curtis", "created_at": "January 21, 2016 at 03:16PM", "created_by": "LelandCurtis", "parent_id": "reply_2985220_Comment_1444535", "id": "reply_2985220_Comment_1444639"}